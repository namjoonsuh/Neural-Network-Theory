# Theory on Neural Network Models

We use this repository to keep track of slides that we are making for a theoretical review on neural network based models. 

## Table of contents

The following is a list of papers that we are working on presentatoin slides. 

  * The PDF files of the corresponding papers are in folder "papers". 
  * The corresponding Latex sources are in folder "slides source files". 

1. Nonparametric regression using deep neural networks with ReLU activation function; J Schmidt-Hieber - arXiv preprint arXiv:1708.06633, 2017 

  * *papers*/1708.06633.pdf 
  * *slides source files*/Hieber_approx.xxx for the functional approximation part
  * *slides source files*/Hieber_Risk.xxx for the minimax estimation rate part 

2. Optimal approximation of piecewise smooth functions using deep ReLU neural networks; P Petersen, F Voigtlaender - Neural Networks, 2018 - Elsevier

  * *papers*/1709.05289.pdf
  * *slides source files*/Petersen.xxx

3. Error bounds for approximations with deep ReLU networks; D Yarotsky - Neural Networks, 2017 - Elsevier

  * *papers*/1610.01145.pdf
  * *slides source files*/Yarotsky.xxx

_The following papers are possibly in the pipeline._

4. Universality of deep convolutional neural networks; DX Zhou - Applied and computational harmonic analysis, 2020 - Elsevier

  * *papers*/1805.10769.pdf

5. Fast learning rates for plug-in classifiers; JY Audibert, AB Tsybakov - The Annals of statistics, 2007

  * *papers*/1183667286.pdf 

6. Optimal aggregation of classifiers in statistical learning; AB Tsybakov - The Annals of Statistics, 2004

  * *papers*/1079120131.pdf 

7. Smooth discrimination analysis; E Mammen, AB Tsybakov - The Annals of Statistics

  * *papers*/1017939240.pdf 
